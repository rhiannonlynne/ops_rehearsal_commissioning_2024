{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cd346756-105f-468a-8e1d-a507cd68384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.time import Time\n",
    "from rubin_scheduler.scheduler.model_observatory import ModelObservatory, KinemModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2c699a8a-b1bf-49ab-898f-ae627827953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the start of the *survey* (and keeping this the same) is important for the Model Observatory and Scheduler,\n",
    "# because this sets an overall dither pattern per night, but also helps track things that may \n",
    "# otherwise change per night ... for SV surveys, might not be totally necessary, but is good practice\n",
    "# (you can change the *day* / mjd that you are simulating, of course, but mjd_start should remain the same)\n",
    "\n",
    "dayobs = '2024-09-09'\n",
    "\n",
    "survey_start = Time(f'{dayobs}T12:00:00', format='isot', scale='utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c66c4021-7594-415f-8244-b86a82906add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunset 60562.936555093154 2024-09-09 22:28:38.360\n",
      "sun_n12_setting 60562.975207073614 2024-09-09 23:24:17.891\n",
      "sun_n18_setting 60562.99454106344 2024-09-09 23:52:08.348\n",
      "sun_n18_rising 60563.39397472935 2024-09-10 09:27:19.417\n",
      "sun_n12_rising 60563.4132887749 2024-09-10 09:55:08.150\n",
      "sunrise 60563.45188789442 2024-09-10 10:50:43.114\n",
      "moonrise 60563.62073250674 2024-09-10 14:53:51.289\n",
      "moonset 60563.19181374041 2024-09-10 04:36:12.707\n",
      "moonphase(%) 46.25\n"
     ]
    }
   ],
   "source": [
    "# Don't have to do this, but can grab almanac information\n",
    "\n",
    "from rubin_scheduler.site_models import Almanac\n",
    "from rubin_scheduler.utils import Site\n",
    "\n",
    "almanac = Almanac(mjd_start = survey_start.mjd)\n",
    "\n",
    "def show_almanac_info(dayobs):\n",
    "    night_info = almanac.get_sunset_info(evening_date=dayobs, longitude=Site('LSST').longitude_rad)\n",
    "    \n",
    "    dd = []\n",
    "    for val, col in zip(night_info, night_info.dtype.names):\n",
    "        if col == 'night':\n",
    "            continue\n",
    "        else:\n",
    "            print(col, val, Time(val, format='mjd', scale='utc').iso)\n",
    "    \n",
    "    # And can check on the lunar phase -- this goes from 0 (new) to 100 (full)\n",
    "    moon_phase = almanac.get_sun_moon_positions(night_info['moonrise'])['moon_phase']\n",
    "    print(f'moonphase(%) {moon_phase.round(2)}')\n",
    "\n",
    "show_almanac_info(dayobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83506b5b-f9d5-49f9-bcbd-009e00e47412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tma_movement(percent=70):\n",
    "    # See https://confluence.lsstcorp.org/display/LSSTCOM/TMA+Motion+Settings\n",
    "    tma = {}\n",
    "    scale = percent / 100.0\n",
    "    tma['azimuth_maxspeed'] = np.min([10.0 * scale, 7.0])\n",
    "    tma['azimuth_accel'] = 10.0 * scale\n",
    "    tma['azimuth_jerk'] = np.max([1.0, 40.0 * scale])\n",
    "    tma['altitude_maxspeed'] = 5.0 * scale\n",
    "    tma['altitude_accel'] = 5.0 * scale\n",
    "    tma['altitude_jerk'] = np.max([1.0, 20.0 * scale])\n",
    "    tma['settle_time'] = 3.0\n",
    "    return tma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fa7ffde-222e-45de-a987-ff23ba387254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotator_movement(percent=70):\n",
    "    # These need confirmation from ROO\n",
    "    # Also it's not clear if they need to be set to the same level as the TMA\n",
    "    rot = {}\n",
    "    rot['maxspeed'] = 5.0 * percent/100.0\n",
    "    rot['accel'] = 1.4 * percent/100.0\n",
    "    rot['jerk'] = 5.0 * percent/100.0\n",
    "    return rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7fa6ebb0-987e-448a-a3c5-54d2a8f2f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some weather telemetry that might be useful\n",
    "from collections import namedtuple\n",
    "\n",
    "class CommissioningSeeingData:\n",
    "    fwhm_500: float = 2.5\n",
    "\n",
    "    def __call__(self, time : Time):\n",
    "        \"\"\"A constant FWHM_500 value\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        time : `astropy.time.Time`\n",
    "            It principle the time for which the seeing is returned,\n",
    "            in practice this argumnet is ignored, and included for\n",
    "            compatibility.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fwhm_500 : `float`\n",
    "            The FWHM at 500nm, in arcseconds.\n",
    "        \"\"\"\n",
    "        return self.fwhm_500\n",
    "\n",
    "WindConditions = namedtuple(\"WindConditions\", [\"speed\", \"direction\"])\n",
    "\n",
    "class CommissioningWindData:\n",
    "    \"\"\"A source of constant wind values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wind_speed : `float`\n",
    "        Wind speed (m/s).\n",
    "    wind_direction : `float`\n",
    "        Direction from which the wind originates. A direction of 0.0 degrees\n",
    "        means the wind originates from the north and 90.0 degrees from the\n",
    "        east (radians).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, wind_speed: float = 5.0, wind_direction: float = 340):\n",
    "        # see also https://sitcomtn-126.lsst.io\n",
    "        # wind direction is typical 330 to 350 degrees\n",
    "        # wind speed will vary -- telescope should try to point out of wind\n",
    "        self.wind_speed = wind_speed\n",
    "        self.wind_direction = wind_direction\n",
    "\n",
    "    def __call__(self, time: Time):\n",
    "        \"\"\"A constant wind conditions\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        time : `astropy.time.Time`\n",
    "            It principle the time for which the wind is returned,\n",
    "            in practice this argument is ignored, and included for\n",
    "            compatibility.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        wind_conditions : `tuple` (`float`, `float`)\n",
    "            A named tuple with the wind speed (m/s) and originating\n",
    "            direction (radians east of north)\n",
    "        \"\"\"\n",
    "        conditions = WindConditions(self.wind_speed, self.wind_direction)\n",
    "        return conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dba3476b-c30b-4c4d-a9ba-436c6869e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MJD for start of simulation\n",
    "\n",
    "mjd_now = night_info['sunset']\n",
    "\n",
    "# Set up model observatory with modified telescope movement and seeing\n",
    "\n",
    "filterlist = ['g', 'r', 'i', 'z', 'y']\n",
    "kinematic_model = KinemModel(mjd0=mjd_now)\n",
    "kinematic_model.setup_camera(readtime=2.4, **rotator_movement(40.))\n",
    "kinematic_model.setup_telescope(**tma_movement(10.0))\n",
    "kinematic_model.mount_filters(filterlist)  # optional, but might be useful with comcam - must be last\n",
    "\n",
    "seeing_data = CommissioningSeeingData()\n",
    "\n",
    "wind_data = CommissioningWindData()\n",
    "\n",
    "observatory = ModelObservatory(mjd=mjd_now, \n",
    "                               mjd_start=survey_start.mjd,\n",
    "                               kinem_model=kinematic_model, # Modified kinematics\n",
    "                               cloud_data='ideal',          # No clouds\n",
    "                               seeing_data=seeing_data,     # Modified seeing\n",
    "                               wind_data=wind_data,         # Add some wind\n",
    "                               downtimes='ideal',           # No downtime\n",
    "                               lax_dome=True,               # dome crawl?\n",
    "                               init_load_length=2,          # size of skybrightness files to load first\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5c790c69-3dd0-4573-9180-cd6318ffe81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So you can see the state of the model observatory at any time .. \n",
    "# Note that this advances the time for the observatory, which will advance it for the Scheduler\n",
    "observatory.mjd = night_info['sun_n18_setting']\n",
    "conditions = observatory.return_conditions()\n",
    "#conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "017ce9d1-8607-4c95-8a6d-07290e823dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your scheduler\n",
    "\n",
    "# Please do make sure to add wind avoidance basis functions, etc. \n",
    "\n",
    "fields = (\n",
    "    (\"Rubin_SV_095_-25\", 95., -25.), # High stellar densty, low extinction\n",
    "    (\"Rubin_SV_125_-15\", 125., -15.), # High stellar densty, low extinction\n",
    "    (\"DESI_SV3_R1\", 179.60, 0.000), # DESI, GAMA, HSC DR2, KiDS-N\n",
    "    (\"Rubin_SV_225_-40\", 225., -40.), # 225 High stellar densty, low extinction\n",
    "    (\"DEEP_A0\", 216, -12.5), # DEEP Solar Systen\n",
    "    (\"Rubin_SV_250_2\", 250., 2.), # 250 High stellar densty, low extinction\n",
    "    (\"Rubin_SV_300_-41\", 300., -41.), # High stellar densty, low extinction \n",
    "    (\"Rubin_SV_280_-48\", 280., -48.), # High stellar densty, low extinction \n",
    "    (\"DEEP_B0\", 310, -19), # DEEP Solar System\n",
    "    (\"ELAIS_S1\", 9.45, -44.0), # ELAIS-S1 LSST DDF\n",
    "    (\"XMM_LSS\", 35.708333, -4.75), # LSST DDF\n",
    "    (\"ECDFS\", 53.125, -28.1), # ECDFS\n",
    "    (\"COSMOS\", 150.1, 2.1819444444444445), # COSMOS\n",
    "    (\"EDFS_A\", 58.9, -49.315), # EDFS_a\n",
    "    (\"EDFS_B\", 63.6, -47.6), # EDFS_b\n",
    ")\n",
    "\n",
    "fields_dict = dict(zip([f[0] for f in fields], [(f[1], f[2]) for f in fields]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2b82a9fa-1ef8-4888-8f97-9ac2951ecbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [True, False, True]\n",
    "any(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8e66d5a6-5004-46fd-88ec-7400037ea833",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I need to update the *FieldSurvey* in rubin_scheduler, but I think it would be something like this: \n",
    "\n",
    "from functools import cached_property\n",
    "from rubin_scheduler.utils import ra_dec2_hpid\n",
    "from rubin_scheduler.scheduler.utils import empty_observation\n",
    "from rubin_scheduler.scheduler.surveys import BaseSurvey\n",
    "\n",
    "\n",
    "class FieldSurvey(BaseSurvey):\n",
    "    \"\"\"A survey class for running deep drilling fields.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    basis_functions : list\n",
    "        List of basis_function objects\n",
    "    detailers : list of rubin_scheduler.scheduler.detailers objects\n",
    "        The detailers to apply to the list of observations.\n",
    "    RA : float\n",
    "        The RA of the field (degrees)\n",
    "    dec : float\n",
    "        The dec of the field to observe (degrees)\n",
    "    sequence : list of observation objects or str (rgizy)\n",
    "        The sequence of observations to take. Can be a string of\n",
    "        list of obs objects.\n",
    "    nvis : list of ints\n",
    "        The number of visits in each filter. Should be same length\n",
    "        as sequence.\n",
    "    exptime : float\n",
    "        The exposure time for visits in grizy.\n",
    "    u_exptime : float\n",
    "        The exposure time for visits in u band\n",
    "    nexp : float\n",
    "        The number of exposures per visit (except u band, which is always 1)\n",
    "    ignore_obs : `list` [`str`] or None\n",
    "        Ignore observations with this string in the `scheduler_note`.\n",
    "        Will ignore observations which match subsets of the string, as well as\n",
    "        the entire string. Ignoring 'mysurvey23' will also ignore 'mysurvey2'.\n",
    "    accept_obs : `list` [`str`] or None\n",
    "        If match_obs is set, then ONLY observations which match these\n",
    "        strings in the `scheduler_note` will be counted for the survey.\n",
    "        A complete match must occur; substrings will not match. (for obs_array too??)\n",
    "    survey_name : `str` or None.\n",
    "        The name to give this survey, for debugging and visualization purposes.\n",
    "        Also propagated to the 'target_name' in the observation.\n",
    "        The default None will construct a name based on the RA/Dec of the field.\n",
    "    scheduler_note : `str` or None\n",
    "        The value to include in the scheduler note. \n",
    "        The scheduler note is for internal, scheduler, use for the purposes of\n",
    "        identifying observations to ignore or include for a survey or feature.\n",
    "    readtime : float \n",
    "        Readout time for computing approximate time of observing\n",
    "        the sequence. (seconds)\n",
    "    filter_change_time : float\n",
    "        Filter change time, on average. Used for computing approximate \n",
    "        time for the observing sequence. (seconds)\n",
    "    nside : float or None\n",
    "        Nside for computing survey basis functions and maps.\n",
    "        The default of None will use rubin_scheduler.utils.set_default_nside().\n",
    "    flush_pad : float\n",
    "        How long to hold observations in the queue after they\n",
    "        were expected to be completed (minutes).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        basis_functions,\n",
    "        RA,\n",
    "        dec,\n",
    "        sequence=\"rgizy\",\n",
    "        nvis=[20, 10, 20, 26, 20],\n",
    "        exptime=30.0,\n",
    "        u_exptime=38.0,\n",
    "        nexp=2,\n",
    "        ignore_obs=None,\n",
    "        accept_obs=None,\n",
    "        survey_name=None,\n",
    "        scheduler_note=None,\n",
    "        readtime=2.4,\n",
    "        filter_change_time=120.0,\n",
    "        nside=None,\n",
    "        flush_pad=30.0,\n",
    "        seed=42,\n",
    "        detailers=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            nside=nside,\n",
    "            basis_functions=basis_functions,\n",
    "            detailers=detailers,\n",
    "            ignore_obs=ignore_obs,\n",
    "        )\n",
    "        self.accept_obs = accept_obs\n",
    "        \n",
    "        random.seed(a=seed)\n",
    "        # Set all basis function equal. \n",
    "        self.basis_weights = np.ones(len(basis_functions)) / len(basis_functions)\n",
    "\n",
    "        self.ra = np.radians(RA)\n",
    "        self.ra_hours = RA / 360.0 * 24.0\n",
    "        self.dec = np.radians(dec)\n",
    "        self.ra_deg, self.dec_deg = RA, dec\n",
    "        \n",
    "        self.survey_name = survey_name\n",
    "        if self.survey_name is None:\n",
    "            self.survey_name = f\"Field {self.ra_deg :.2f} {self.dec_deg :.2f}\"\n",
    "        self.scheduler_note = scheduler_note\n",
    "        if self.scheduler_note is None:\n",
    "            self.scheduler_note = self.survey_name\n",
    "         \n",
    "        self.reward_value = reward_value\n",
    "        self.flush_pad = flush_pad / 60.0 / 24.0  # To days\n",
    "        self.filter_sequence = []\n",
    "        if isinstance(sequence, str):\n",
    "            self.observations = []\n",
    "            for num, filtername in zip(nvis, sequence):\n",
    "                for j in range(num):\n",
    "                    obs = empty_observation()\n",
    "                    obs[\"filter\"] = filtername\n",
    "                    if filtername == \"u\":\n",
    "                        obs[\"exptime\"] = u_exptime\n",
    "                    else:\n",
    "                        obs[\"exptime\"] = exptime\n",
    "                    obs[\"RA\"] = self.ra\n",
    "                    obs[\"dec\"] = self.dec\n",
    "                    if filtername == \"u\":\n",
    "                        obs[\"nexp\"] = 1\n",
    "                    else:\n",
    "                        obs[\"nexp\"] = nexp\n",
    "                    obs[\"target\"] = self.survey_name\n",
    "                    obs[\"note\"] = self.scheduler_note\n",
    "                    self.observations.append(obs)\n",
    "        else:\n",
    "            self.observations = sequence\n",
    "\n",
    "        # Let's just make this an array for ease of use\n",
    "        self.observations = np.concatenate(self.observations)\n",
    "        order = np.argsort(self.observations[\"filter\"])\n",
    "        self.observations = self.observations[order]\n",
    "\n",
    "        n_filter_change = np.size(np.unique(self.observations[\"filter\"]))\n",
    "\n",
    "        # Make an estimate of how long a seqeunce will take.\n",
    "        # Assumes no major rotational or spatial\n",
    "        # dithering slowing things down.\n",
    "        self.approx_time = (\n",
    "            np.sum(self.observations[\"exptime\"] + readtime * self.observations[\"nexp\"]) / 3600.0 / 24.0\n",
    "            + filter_change_time * n_filter_change / 3600.0 / 24.0\n",
    "        )  # to days\n",
    "\n",
    "        if self.reward_value is None:\n",
    "            self.extra_features[\"Ntot\"] = features.NObsSurvey()\n",
    "            self.extra_features[\"N_survey\"] = features.NObsSurvey(note=self.scheduler_note)\n",
    "\n",
    "    @cached_property\n",
    "    def roi_hpid(self):\n",
    "        hpid = ra_dec2_hpid(self.nside, np.degrees(self.ra), np.degrees(self.dec))\n",
    "        return hpid\n",
    "\n",
    "    def check_continue(self, observation, conditions):\n",
    "        # feasibility basis functions?\n",
    "        \"\"\"\n",
    "        This method enables external calls to check if a given\n",
    "        observations that belongs to this survey is\n",
    "        feasible or not. This is called once a sequence has\n",
    "        started to make sure it can continue.\n",
    "\n",
    "        XXX--TODO:  Need to decide if we want to develop check_continue,\n",
    "        or instead hold the sequence in the survey, and be able to check\n",
    "        it that way. \n",
    "        \"\"\"\n",
    "        result = True\n",
    "        return result\n",
    "\n",
    "    def add_observation(self, observation, **kwargs):\n",
    "        \"\"\"Add observation one at a time.\"\"\"\n",
    "        # Check each posible ignore string\n",
    "        checks = [io not in str(observation[\"note\"]) for io in self.ignore_obs]\n",
    "        passed_ignore = all(checks)\n",
    "        passed_accept = True\n",
    "        if passed_ignore and self.accept_obs is not None:\n",
    "            # Check if this observation matches any accept string.\n",
    "            checks = [io == str(observation[\"note\"]) for io in self.accept_obs]\n",
    "            passed_accept = any(checks)\n",
    "        # I think here I have to assume observation is an\n",
    "        # array and not a dict.\n",
    "        if passed_ignore and passed_accept:\n",
    "            for feature in self.extra_features:\n",
    "                self.extra_features[feature].add_observation(observation, **kwargs)\n",
    "            for bf in self.extra_basis_functions:\n",
    "                self.extra_basis_functions[bf].add_observation(observation, **kwargs)\n",
    "            for bf in self.basis_functions:\n",
    "                bf.add_observation(observation, **kwargs)\n",
    "            for detailer in self.detailers:\n",
    "                detailer.add_observation(observation, **kwargs)\n",
    "            self.reward_checked = False\n",
    "\n",
    "    def add_observations_array(self, observations_array_in, observations_hpid_in):\n",
    "        \"\"\"Add an array of observations rather than one at a time\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observations_array_in : np.array\n",
    "            An array of completed observations\n",
    "            (with columns like\n",
    "            rubin_scheduler.scheduler.utils.empty_observation).\n",
    "        observations_hpid_in : np.array\n",
    "            Same as observations_array_in, but larger and with an\n",
    "            additional column for HEALpix id. Each observation is\n",
    "            listed mulitple times, once for every HEALpix it overlaps.\n",
    "        \"\"\"\n",
    "        # Just to be sure things are sorted\n",
    "        observations_array_in.sort(order=\"mjd\")\n",
    "        observations_hpid_in.sort(order=\"mjd\")\n",
    "\n",
    "        # Copy so we don't prune things for other survey objects\n",
    "        observations_array = observations_array_in.copy()\n",
    "        observations_hpid = observations_hpid_in.copy()\n",
    "\n",
    "        for ig in self.ignore_obs:\n",
    "            not_ignore = np.where(np.char.find(observations_array[\"note\"], ig) == -1)[0]\n",
    "            observations_array = observations_array[not_ignore]\n",
    "\n",
    "            not_ignore = np.where(np.char.find(observations_hpid[\"note\"], ig) == -1)[0]\n",
    "            observations_hpid = observations_hpid[not_ignore]\n",
    "\n",
    "        for acc in self.accept_obs:\n",
    "            accept = np.where(np.char.find(observations_array[\"note\"], acc) == 1)[0]\n",
    "            observations_array = observations_array[accept]\n",
    "\n",
    "            accept = np.where(np.char.find(observations_hpid[\"note\"], acc) == 1)[0]\n",
    "            observations_hpid = observations_hpid[accept]\n",
    "            \n",
    "        for feature in self.extra_features:\n",
    "            self.extra_features[feature].add_observations_array(observations_array, observations_hpid)\n",
    "        for bf in self.extra_basis_functions:\n",
    "            self.extra_basis_functions[bf].add_observations_array(observations_array, observations_hpid)\n",
    "        for bf in self.basis_functions:\n",
    "            bf.add_observations_array(observations_array, observations_hpid)\n",
    "        for detailer in self.detailers:\n",
    "            detailer.add_observations_array(observations_array, observations_hpid)\n",
    "        self.reward_checked = False\n",
    "\n",
    "    def calc_reward_function(self, conditions):\n",
    "        self.reward_checked = True\n",
    "        indx = ra_dec2_hpid(self.nside, self.ra_deg, self.dec_deg)\n",
    "        if self._check_feasibility(conditions):\n",
    "            self.reward = 0\n",
    "            for bf, weight in zip(self.basis_functions, self.basis_weights):\n",
    "                basis_value = bf(conditions, indx=indx)\n",
    "                self.reward += basis_value * weight\n",
    "\n",
    "            if not np.isscalar(self.reward):\n",
    "                self.reward = np.sum(self.reward[indx])\n",
    "\n",
    "                if np.any(np.isinf(self.reward)):\n",
    "                    self.reward = np.inf\n",
    "        else:\n",
    "            # If not feasible, negative infinity reward\n",
    "            self.reward = -np.inf\n",
    "\n",
    "        return self.reward\n",
    "\n",
    "    def generate_observations_rough(self, conditions):\n",
    "        result = []\n",
    "        if self._check_feasibility(conditions):\n",
    "            result = copy.deepcopy(self.observations)\n",
    "\n",
    "            # Set the flush_by\n",
    "            result[\"flush_by_mjd\"] = conditions.mjd + self.approx_time + self.flush_pad\n",
    "\n",
    "            # remove filters that are not mounted\n",
    "            mask = np.isin(result[\"filter\"], conditions.mounted_filters)\n",
    "            result = result[mask]\n",
    "            # Put current loaded filter first\n",
    "            ind1 = np.where(result[\"filter\"] == conditions.current_filter)[0]\n",
    "            ind2 = np.where(result[\"filter\"] != conditions.current_filter)[0]\n",
    "            result = result[ind1.tolist() + (ind2.tolist())]\n",
    "\n",
    "            # convert to list of array. \n",
    "            final_result = [\n",
    "                row.reshape(\n",
    "                    1,\n",
    "                )\n",
    "                for row in result\n",
    "            ]\n",
    "            result = final_result\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"<{self.__class__.__name__} survey_name='{self.survey_name}'\"\n",
    "            f\", RA={self.ra}, dec={self.dec} at {hex(id(self))}>\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9025b342-4d8d-4490-91a3-26dc99a9a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "## field survey to be tested .. this should make it unnecessary to specify particular notes in features for basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd5d8f-a83c-4fec-9d4d-d1531a1468a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
